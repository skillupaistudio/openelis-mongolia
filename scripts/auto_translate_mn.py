#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
–ê–≤—Ç–æ–º–∞—Ç –ú–æ–Ω–≥–æ–ª –æ—Ä—á—É—É–ª–≥–∞ - OpenELIS
–ë“Ø—Ö –∞–Ω–≥–ª–∏ key-–≥ –º–æ–Ω–≥–æ–ª —Ä—É—É –æ—Ä—á—É—É–ª–Ω–∞
"""

import json
import sys
from pathlib import Path

# –ú–µ–¥–∏—Ü–∏–Ω—ã –Ω—ç—Ä —Ç–æ–º—ä—ë–æ —Ç–æ–ª—å –±–∏—á–∏–≥
MEDICAL_TERMS = {
    # –î—ç—ç–∂–∏–π–Ω —Ç”©—Ä”©–ª
    "Blood": "–¶—É—Å",
    "Urine": "–®—ç—ç—Å", 
    "Stool": "–ë–∞–∞—Å",
    "Sputum": "–¶—ç—Ä—ç–≥—Ü–ª—ç—Ö",
    "Serum": "–°–∏–π–≤—ç–Ω",
    "Plasma": "–ü–ª–∞–∑–º–∞",
    "Saliva": "–®“Ø–ª—Å",
    "CSF": "–ù—É–≥–∞—Å–Ω—ã —à–∏–Ω–≥—ç–Ω",
    "Tissue": "–≠–¥",
    "Swab": "–ê—Ä—á–¥–∞—Å",
    
    # –®–∏–Ω–∂–∏–ª–≥—ç—ç–Ω–∏–π —Ç”©—Ä”©–ª
    "Hematology": "–¶—É—Å–Ω—ã —à–∏–Ω–∂–∏–ª–≥—ç—ç",
    "Biochemistry": "–ë–∏–æ—Ö–∏–º–∏",
    "Microbiology": "–ù—è–Ω —Å—É–¥–ª–∞–ª",
    "Immunology": "–î–∞—Ä—Ö–ª–∞–ª —Å—É–¥–ª–∞–ª",
    "Serology": "–°–∏–π–≤—ç–Ω —Å—É–¥–ª–∞–ª",
    "Virology": "–í–∏—Ä—É—Å —Å—É–¥–ª–∞–ª",
    "Parasitology": "–®–∏–º—ç–≥—á —Å—É–¥–ª–∞–ª",
    "Cytology": "–≠—Å —Å—É–¥–ª–∞–ª",
    "Histology": "–≠–¥ —Å—É–¥–ª–∞–ª",
    "Molecular Biology": "–ú–æ–ª–µ–∫—É–ª –±–∏–æ–ª–æ–≥–∏",
    
    # “Æ—Ä –¥“Ø–Ω
    "Positive": "–≠–µ—Ä—ç–≥",
    "Negative": "–°”©—Ä”©–≥",
    "Normal": "–•—ç–≤–∏–π–Ω",
    "Abnormal": "–•—ç–≤–∏–π–Ω –±—É—Å",
    "Pending": "–•“Ø–ª—ç—ç–≥–¥—ç–∂ –±—É–π",
    "In Progress": "–ì“Ø–π—Ü—ç—Ç–≥—ç–∂ –±—É–π",
    "Completed": "–î—É—É—Å—Å–∞–Ω",
    "Validated": "–ë–∞—Ç–∞–ª–≥–∞–∞–∂—Å–∞–Ω",
    "Rejected": "–¢–∞—Ç–≥–∞–ª–∑—Å–∞–Ω",
    
    # –≠–º–Ω—ç–ª–≥–∏–π–Ω “Ø–∑“Ø“Ø–ª—ç–ª—Ç
    "Hemoglobin": "–ì–µ–º–æ–≥–ª–æ–±–∏–Ω",
    "Glucose": "–ì–ª—é–∫–æ–∑",
    "Cholesterol": "–•–æ–ª–µ—Å—Ç–µ—Ä–æ–ª",
    "Creatinine": "–ö—Ä–µ–∞—Ç–∏–Ω–∏–Ω",
    "Bilirubin": "–ë–∏–ª–∏—Ä—É–±–∏–Ω",
    "WBC": "–¶–∞–≥–∞–∞–Ω —Ü—É—Å",
    "RBC": "–£–ª–∞–∞–Ω —Ü—É—Å",
    "Platelet": "–¢—Ä–æ–º–±–æ—Ü–∏—Ç",
}

# –ï—Ä”©–Ω—Ö–∏–π –æ—Ä—á—É—É–ª–≥—ã–Ω —Ç–æ–ª—å
COMMON_TRANSLATIONS = {
    # “Æ–π–ª–¥—ç–ª
    "Add": "–ù—ç–º—ç—Ö",
    "Edit": "–ó–∞—Å–∞—Ö",
    "Delete": "–£—Å—Ç–≥–∞—Ö",
    "Save": "–•–∞–¥–≥–∞–ª–∞—Ö",
    "Cancel": "–¶—É—Ü–ª–∞—Ö",
    "Submit": "–ò–ª–≥—ç—ç—Ö",
    "Search": "–•–∞–π—Ö",
    "Print": "–•—ç–≤–ª—ç—Ö",
    "Back": "–ë—É—Ü–∞—Ö",
    "Next": "–î–∞—Ä–∞–∞—Ö",
    "Previous": "”®–º–Ω”©—Ö",
    "Finish": "–î—É—É—Å–≥–∞—Ö",
    "Close": "–•–∞–∞—Ö",
    "Accept": "–ó”©–≤—à”©”©—Ä”©—Ö",
    "Reject": "–¢–∞—Ç–≥–∞–ª–∑–∞—Ö",
    "Confirm": "–ë–∞—Ç–∞–ª–≥–∞–∞–∂—É—É–ª–∞—Ö",
    "View": "–•–∞—Ä–∞—Ö",
    "Load": "–ê—á–∞–∞–ª–∞—Ö",
    "Export": "–≠–∫—Å–ø–æ—Ä—Ç–ª–æ—Ö",
    "Import": "–ò–º–ø–æ—Ä—Ç–ª–æ—Ö",
    
    # –ï—Ä”©–Ω—Ö–∏–π
    "Home": "–ù“Ø“Ø—Ä",
    "Patient": "”®–≤—á—Ç”©–Ω",
    "Order": "–ó–∞—Ö–∏–∞–ª–≥–∞",
    "Sample": "–î—ç—ç–∂",
    "Test": "–®–∏–Ω–∂–∏–ª–≥—ç—ç",
    "Result": "“Æ—Ä –¥“Ø–Ω",
    "Report": "–¢–∞–π–ª–∞–Ω",
    "Admin": "–£–¥–∏—Ä–¥–ª–∞–≥–∞",
    "Help": "–¢—É—Å–ª–∞–º–∂",
    "Version": "–•—É–≤–∏–ª–±–∞—Ä",
    "Date": "–û–≥–Ω–æ–æ",
    "Time": "–¶–∞–≥",
    "Status": "–¢”©–ª”©–≤",
    "Name": "–ù—ç—Ä",
    "Description": "–¢–∞–π–ª–±–∞—Ä",
    "Value": "–£—Ç–≥–∞",
    "Type": "–¢”©—Ä”©–ª",
    "Active": "–ò–¥—ç–≤—Ö–∏—Ç—ç–π",
    "Inactive": "–ò–¥—ç–≤—Ö–≥“Ø–π",
    
    # –•“Ø–º“Ø“Ø—Å
    "First Name": "–ù—ç—Ä",
    "Last Name": "–û–≤–æ–≥",
    "Gender": "–•“Ø–π—Å",
    "Male": "–≠—Ä—ç–≥—Ç—ç–π",
    "Female": "–≠–º—ç–≥—Ç—ç–π",
    "Birth Date": "–¢”©—Ä—Å”©–Ω –æ–≥–Ω–æ–æ",
    "Age": "–ù–∞—Å",
    "Phone": "–£—Ç–∞—Å",
    "Email": "–¶–∞—Ö–∏–º —à—É—É–¥–∞–Ω",
    "Address": "–•–∞—è–≥",
    
    # –ú–µ—Å—Å–µ–∂
    "Success": "–ê–º–∂–∏–ª—Ç—Ç–∞–π",
    "Error": "–ê–ª–¥–∞–∞",
    "Warning": "–ê–Ω—Ö–∞–∞—Ä—É—É–ª–≥–∞",
    "Info": "–ú—ç–¥—ç—ç–ª—ç–ª",
    "Saved successfully": "–ê–º–∂–∏–ª—Ç—Ç–∞–π —Ö–∞–¥–≥–∞–ª–∞–≥–¥–ª–∞–∞",
    "Deleted successfully": "–ê–º–∂–∏–ª—Ç—Ç–∞–π —É—Å—Ç–≥–∞–≥–¥–ª–∞–∞",
    "Are you sure": "–¢–∞ –∏—Ç–≥—ç–ª—Ç—ç–π –±–∞–π–Ω–∞ —É—É",
    "Required": "–ó–∞–∞–≤–∞–ª",
    "Optional": "–ó–∞–∞–≤–∞–ª –±–∏—à",
    "Yes": "–¢–∏–π–º",
    "No": "“Æ–≥“Ø–π",
    "OK": "–û–ö",
    "Access Denied": "–ù—ç–≤—Ç—Ä—ç—Ö —ç—Ä—Ö–≥“Ø–π",
}


def smart_translate(english_text):
    """
    –ê–Ω–≥–ª–∏ —Ç–µ–∫—Å—Ç–∏–π–≥ –º–æ–Ω–≥–æ–ª —Ä—É—É —É—Ö–∞–∞–ª–∞–≥ –æ—Ä—á—É—É–ª–Ω–∞
    """
    # –•–æ–æ—Å–æ–Ω —ç—Å–≤—ç–ª –º–∞—à –±–æ–≥–∏–Ω–æ —Ç–µ–∫—Å—Ç
    if not english_text or len(english_text) < 2:
        return english_text
    
    # –≠—Ö–ª—ç—ç–¥ –±“Ø—Ç—ç–Ω ”©–≥“Ø“Ø–ª–±—ç—Ä—ç—ç—Ä —Ö–∞–π—Ö
    if english_text in MEDICAL_TERMS:
        return MEDICAL_TERMS[english_text]
    if english_text in COMMON_TRANSLATIONS:
        return COMMON_TRANSLATIONS[english_text]
    
    # “Æ–≥ –±“Ø—Ä—ç—ç—Ä —Ö–∞–π–∂ –æ—Ä—á—É—É–ª–∞—Ö
    words = english_text.split()
    translated_words = []
    
    for word in words:
        # –¶—ç–≥, —Ç–∞—Å–ª–∞–ª –∑—ç—Ä–≥–∏–π–≥ —Å–∞–ª–≥–∞—Ö
        clean_word = word.strip('.,!?:;()[]{}\'\"')
        
        if clean_word in MEDICAL_TERMS:
            translated_words.append(MEDICAL_TERMS[clean_word])
        elif clean_word in COMMON_TRANSLATIONS:
            translated_words.append(COMMON_TRANSLATIONS[clean_word])
        else:
            # –û—Ä—á—É—É–ª–∞–≥–¥–∞–∞–≥“Ø–π “Ø–ª–¥—ç—ç—Ö (—Ç–µ—Ö–Ω–∏–∫ –Ω—ç—Ä —Ç–æ–º—ä—ë–æ)
            translated_words.append(word)
    
    return ' '.join(translated_words)


def translate_all():
    """
    en.json-–∏–π–Ω –±“Ø—Ö key-–≥ mn.json —Ä—É—É –æ—Ä—á—É—É–ª–Ω–∞
    """
    base_dir = Path(__file__).parent.parent
    en_file = base_dir / 'frontend' / 'src' / 'languages' / 'en.json'
    mn_file = base_dir / 'frontend' / 'src' / 'languages' / 'mn.json'
    
    # –ê–Ω–≥–ª–∏ —Ñ–∞–π–ª —É–Ω—à–∏x
    print(f"üìñ –£–Ω—à–∏–∂ –±–∞–π–Ω–∞: {en_file}")
    with open(en_file, 'r', encoding='utf-8') as f:
        en_data = json.load(f)
    
    # –û–¥–æ–æ–≥–∏–π–Ω –º–æ–Ω–≥–æ–ª —Ñ–∞–π–ª —É–Ω—à–∏x (—Ö—ç—Ä—ç–≤ –±–∞–π–≤–∞–ª)
    mn_data = {}
    if mn_file.exists():
        print(f"üìñ –û–¥–æ–æ–≥–∏–π–Ω –º–æ–Ω–≥–æ–ª –æ—Ä—á—É—É–ª–≥–∞: {mn_file}")
        with open(mn_file, 'r', encoding='utf-8') as f:
            mn_data = json.load(f)
    
    print(f"\nüìä –¢–æ–æ:")
    print(f"   –ê–Ω–≥–ª–∏: {len(en_data)} key")
    print(f"   –ú–æ–Ω–≥–æ–ª (–æ–¥–æ–æ): {len(mn_data)} key")
    print(f"   –î—É—Ç—É—É: {len(en_data) - len(mn_data)} key")
    
    # –û—Ä—á—É—É–ª–≥–∞ —ç—Ö–ª“Ø“Ø–ª—ç—Ö
    print(f"\nüîÑ –û—Ä—á—É—É–ª–≥–∞ —ç—Ö—ç–ª–∂ –±–∞–π–Ω–∞...\n")
    
    translated_count = 0
    skipped_count = 0
    
    for key, english_value in en_data.items():
        # –ê–ª—å —Ö—ç–¥–∏–π–Ω –æ—Ä—á—É—É–ª—Å–∞–Ω –±–æ–ª –∞–ª–≥–∞—Å–∞—Ö
        if key in mn_data:
            skipped_count += 1
            continue
        
        # –û—Ä—á—É—É–ª–∞—Ö
        mongolian_value = smart_translate(english_value)
        mn_data[key] = mongolian_value
        translated_count += 1
        
        # Progress —Ö–∞—Ä—É—É–ª–∞—Ö (—Ö—ç—Ä—ç–≤ 100 key –±“Ø—Ä)
        if translated_count % 100 == 0:
            print(f"   ‚úÖ {translated_count} key –æ—Ä—á—É—É–ª–∞–≥–¥–ª–∞–∞...")
    
    print(f"\nüìä –î“Ø–Ω:")
    print(f"   ‚úÖ –®–∏–Ω—ç—ç—Ä –æ—Ä—á—É—É–ª—Å–∞–Ω: {translated_count}")
    print(f"   ‚è≠Ô∏è  –ê–ª–≥–∞—Å—Å–∞–Ω (”©–º–Ω”© –Ω—å –æ—Ä—á—É—É–ª—Å–∞–Ω): {skipped_count}")
    print(f"   üìù –ù–∏–π—Ç: {len(mn_data)} key")
    
    # –•–∞–¥–≥–∞–ª–∞—Ö
    print(f"\nüíæ –•–∞–¥–≥–∞–ª–∂ –±–∞–π–Ω–∞: {mn_file}")
    with open(mn_file, 'w', encoding='utf-8') as f:
        json.dump(mn_data, f, ensure_ascii=False, indent=2)
    
    print(f"\n‚úÖ –ê–º–∂–∏–ª—Ç—Ç–∞–π –¥—É—É—Å–ª–∞–∞!")
    print(f"   Coverage: {len(mn_data)/len(en_data)*100:.1f}%")
    
    return translated_count


if __name__ == '__main__':
    try:
        translate_all()
    except Exception as e:
        print(f"\n‚ùå –ê–ª–¥–∞–∞: {e}", file=sys.stderr)
        sys.exit(1)
